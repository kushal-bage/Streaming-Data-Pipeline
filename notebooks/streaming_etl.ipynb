{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Real Time Data Engineering Projects**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£ (end-to-end) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á data engineering pipeline ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô ingestion, streaming, processing ‡πÑ‡∏õ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô real-time processing ‡πÅ‡∏•‡∏∞ containerized deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏£‡∏∞‡∏ö‡∏ö (System Architecture)**\n",
    "\n",
    "‡∏°‡∏µ component ‡∏´‡∏•‡∏±‡∏Å‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:\n",
    "\n",
    "- **Data Source**: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å API ‡πÄ‡∏ä‡πà‡∏ô randomuser.me ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á (dummy data) \n",
    "\n",
    "- **Apache Airflow**: ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà orchestration ‡∏Ç‡∏≠‡∏á pipeline ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà fetch ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏ô PostgreSQL \n",
    "\n",
    "- **Kafka + Zookeeper**: ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö streaming ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å PostgreSQL ‡πÑ‡∏õ‡∏¢‡∏±‡∏á processing engine \n",
    "\n",
    "- **Control Center & Schema Registry**: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏π‡πÅ‡∏• schema ‡πÅ‡∏•‡∏∞ monitoring Kafka streams \n",
    "\n",
    "- **Apache Spark**: ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (stream processing) ‡∏ú‡πà‡∏≤‡∏ô cluster (master/worker nodes) \n",
    "\n",
    "- **Cassandra**: ‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Orchestration: Apache Airflow\n",
    "\n",
    "- Streaming: Apache Kafka & Zookeeper\n",
    "\n",
    "- Processing: Apache Spark\n",
    "\n",
    "- Storage: PostgreSQL (‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•), Cassandra (‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•)\n",
    "\n",
    "- Containerization: Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå **Kafka ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Data Engineer)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1. Kafka ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?**\n",
    "\n",
    "- Kafka = ‡∏£‡∏∞‡∏ö‡∏ö distributed event streaming platform\n",
    "  ‚Üí ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á, ‡πÄ‡∏Å‡πá‡∏ö ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö real-time\n",
    "\n",
    "- ‡∏°‡∏±‡∏ô‡∏ó‡∏≥‡∏ï‡∏±‡∏ß‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô message broker (‡∏ó‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏≤‡∏á)\n",
    "\n",
    "- ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞‡πÉ‡∏ô‡∏á‡∏≤‡∏ô real-time analytics, log streaming, data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2. ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏´‡∏•‡∏±‡∏Å (Concepts)**\n",
    "\n",
    "‡∏•‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏õ‡πá‡∏ô \"‡∏´‡πâ‡∏≠‡∏á chat\" üëá\n",
    "\n",
    "- **Producer** ‚Üí ‡∏Ñ‡∏ô‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô Kafka)\n",
    "\n",
    "- **Consumer** ‚Üí ‡∏Ñ‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÉ‡∏ä‡πâ)\n",
    "\n",
    "- **Topic** ‚Üí ‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ (channel ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á/‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)\n",
    "\n",
    "- **Broker** ‚Üí Server ‡∏Ç‡∏≠‡∏á Kafka ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö topic\n",
    "\n",
    "- **Cluster** ‚Üí ‡∏Å‡∏•‡∏∏‡πà‡∏° broker ‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏ï‡∏±‡∏ß\n",
    "\n",
    "- **Partition** ‚Üí ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á topic ‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠ scale (‡πÅ‡∏ï‡πà‡∏•‡∏∞ partition ‡∏Ñ‡∏∑‡∏≠‡∏ó‡πà‡∏≠‡πÅ‡∏¢‡∏Å)\n",
    "\n",
    "- **Offset** ‚Üí ‡πÄ‡∏•‡∏Ç‡∏ö‡∏≠‡∏Å‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡∏≠‡∏á message ‡πÉ‡∏ô partition\n",
    "\n",
    "üëâ Keyword: Publish‚ÄìSubscribe system\n",
    "Producer ‡∏¢‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Üí Kafka ‚Üí Consumer ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3. Kafka Data Flow**\n",
    "\n",
    "1. Producer ‡∏™‡∏£‡πâ‡∏≤‡∏á event ‚Üí ‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏ó‡∏µ‡πà Kafka topic\n",
    "\n",
    "2. Kafka ‡πÄ‡∏Å‡πá‡∏ö event ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô log ‡πÅ‡∏ö‡∏ö append-only\n",
    "\n",
    "3. Consumer subscribe topic ‚Üí ‡∏≠‡πà‡∏≤‡∏ô event ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö offset\n",
    "\n",
    "4. Data ‡∏ñ‡∏π‡∏Å process ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ DB, Data Lake, Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö version ‡∏Ç‡∏≠‡∏á Python ‡πÅ‡∏•‡∏∞ Spark ‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å Docker Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.6\n",
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.5.1\n",
      "      /_/\n",
      "                        \n",
      "Using Scala version 2.12.18, OpenJDK 64-Bit Server VM, 11.0.28\n",
      "Branch HEAD\n",
      "Compiled by user heartsavior on 2024-02-15T11:24:58Z\n",
      "Revision fd86f85e181fc2dc0f50a096855acf83a6cc5d9c\n",
      "Url https://github.com/apache/spark\n",
      "Type --help for more information.\n"
     ]
    }
   ],
   "source": [
    "!python3 --version\n",
    "!spark-submit --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Mock Streaming data ‡∏à‡∏≤‡∏Å API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_data():\n",
    "    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Random User\n",
    "    res = requests.get(\"https://randomuser.me/api/\") # ‡πÄ‡∏ß‡∏•‡∏≤‡∏î‡∏∂‡∏á data ‡∏°‡∏≤‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô\n",
    "    res = res.json() # ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å json ‡πÄ‡∏õ‡πá‡∏ô dict\n",
    "    res = res['results'][0]\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"gender\": \"male\",\n",
      "   \"name\": {\n",
      "      \"title\": \"Mr\",\n",
      "      \"first\": \"Tarosik\",\n",
      "      \"last\": \"Negrebeckiy\"\n",
      "   },\n",
      "   \"location\": {\n",
      "      \"street\": {\n",
      "         \"number\": 3043,\n",
      "         \"name\": \"Obolonska naberezhna\"\n",
      "      },\n",
      "      \"city\": \"Yampil\",\n",
      "      \"state\": \"Kirovogradska\",\n",
      "      \"country\": \"Ukraine\",\n",
      "      \"postcode\": 19787,\n",
      "      \"coordinates\": {\n",
      "         \"latitude\": \"78.7005\",\n",
      "         \"longitude\": \"-77.0538\"\n",
      "      },\n",
      "      \"timezone\": {\n",
      "         \"offset\": \"-3:00\",\n",
      "         \"description\": \"Brazil, Buenos Aires, Georgetown\"\n",
      "      }\n",
      "   },\n",
      "   \"email\": \"tarosik.negrebeckiy@example.com\",\n",
      "   \"login\": {\n",
      "      \"uuid\": \"d954af71-fb65-48fc-87c1-6dd70445516b\",\n",
      "      \"username\": \"silvercat440\",\n",
      "      \"password\": \"jaeger\",\n",
      "      \"salt\": \"0TztG8YW\",\n",
      "      \"md5\": \"9497323c25648072070b1fbb1036d6ef\",\n",
      "      \"sha1\": \"c2a147f0372b52cd7d1ed55172cce353e0aad4d5\",\n",
      "      \"sha256\": \"55b88da5b1c27e332ac2bccfcb3edd91b3f3932b5b996ef8600b790d84ba4c1a\"\n",
      "   },\n",
      "   \"dob\": {\n",
      "      \"date\": \"1992-06-03T17:16:32.359Z\",\n",
      "      \"age\": 33\n",
      "   },\n",
      "   \"registered\": {\n",
      "      \"date\": \"2018-10-07T13:35:34.125Z\",\n",
      "      \"age\": 6\n",
      "   },\n",
      "   \"phone\": \"(066) H23-3047\",\n",
      "   \"cell\": \"(067) V44-4916\",\n",
      "   \"id\": {\n",
      "      \"name\": \"\",\n",
      "      \"value\": null\n",
      "   },\n",
      "   \"picture\": {\n",
      "      \"large\": \"https://randomuser.me/api/portraits/men/49.jpg\",\n",
      "      \"medium\": \"https://randomuser.me/api/portraits/med/men/49.jpg\",\n",
      "      \"thumbnail\": \"https://randomuser.me/api/portraits/thumb/men/49.jpg\"\n",
      "   },\n",
      "   \"nat\": \"UA\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(get_data(), indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def format_data(res):\n",
    "    # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    data = {}\n",
    "    location = res['location']\n",
    "    data['id'] = str(uuid.uuid4())\n",
    "    data['first_name'] = res['name']['first']\n",
    "    data['last_name'] = res['name']['last']\n",
    "    data['gender'] = res['gender']\n",
    "    data['address'] = f\"{str(location['street']['number'])} {location['street']['name']}, \" \\\n",
    "                      f\"{location['city']}, {location['state']}, {location['country']}\"\n",
    "    data['post_code'] = location['postcode']\n",
    "    data['email'] = res['email']\n",
    "    data['username'] = res['login']['username']\n",
    "    data['dob'] = res['dob']['date']\n",
    "    data['registered_date'] = res['registered']['date']\n",
    "    data['phone'] = res['phone']\n",
    "    data['picture'] = res['picture']['medium']\n",
    "\n",
    "    print(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'f5856054-6050-429c-8df3-09732c2d180e', 'first_name': 'Milivoje', 'last_name': 'Bla≈æiƒá', 'gender': 'male', 'address': '8494 Drage Vukiƒáeviƒáa, Mitrovica, Central Banat, Serbia', 'post_code': 27797, 'email': 'milivoje.blazic@example.com', 'username': 'purpleelephant477', 'dob': '1961-11-08T19:17:06.004Z', 'registered_date': '2014-04-15T05:05:58.966Z', 'phone': '021-3057-164', 'picture': 'https://randomuser.me/api/portraits/med/men/67.jpg'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'f5856054-6050-429c-8df3-09732c2d180e',\n",
       " 'first_name': 'Milivoje',\n",
       " 'last_name': 'Bla≈æiƒá',\n",
       " 'gender': 'male',\n",
       " 'address': '8494 Drage Vukiƒáeviƒáa, Mitrovica, Central Banat, Serbia',\n",
       " 'post_code': 27797,\n",
       " 'email': 'milivoje.blazic@example.com',\n",
       " 'username': 'purpleelephant477',\n",
       " 'dob': '1961-11-08T19:17:06.004Z',\n",
       " 'registered_date': '2014-04-15T05:05:58.966Z',\n",
       " 'phone': '021-3057-164',\n",
       " 'picture': 'https://randomuser.me/api/portraits/med/men/67.jpg'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_data(get_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mock Api Streaming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_data():\n",
    "    import json\n",
    "    from kafka import KafkaProducer\n",
    "    import time\n",
    "    import logging\n",
    "\n",
    "    producer = KafkaProducer(bootstrap_servers=['broker:29092'], max_block_ms=5000) # ‡∏™‡∏£‡πâ‡∏≤‡∏á KafkaProducer ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏ä‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡πÉ‡∏ô Kafka Boker\n",
    "    curr_time = time.time() # real time\n",
    "\n",
    "    while True:\n",
    "        if time.time() > curr_time + 10: # 1 minute\n",
    "            break\n",
    "        try:\n",
    "            res = get_data()\n",
    "            res = format_data(res)\n",
    "\n",
    "            print(res)\n",
    "            producer.send('users_created', json.dumps(res).encode('utf-8')) # ‡∏™‡πà‡∏á res ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô json ‡πÑ‡∏õ‡πÉ‡∏´‡πâ boker\n",
    "        except Exception as e:\n",
    "            logging.error(f'An error occured: {e}')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '339be22f-558c-4a43-8484-21bc6d72ecc7', 'first_name': 'Marcos', 'last_name': 'Ulloa', 'gender': 'male', 'address': '7966 Retorno Malta, General Zaragoza, Ciudad de Mexico, Mexico', 'post_code': 11288, 'email': 'marcos.ulloa@example.com', 'username': 'tinykoala438', 'dob': '1997-07-24T14:44:37.446Z', 'registered_date': '2019-04-17T12:39:17.771Z', 'phone': '(641) 501 2368', 'picture': 'https://randomuser.me/api/portraits/med/men/22.jpg'}\n",
      "{'id': '339be22f-558c-4a43-8484-21bc6d72ecc7', 'first_name': 'Marcos', 'last_name': 'Ulloa', 'gender': 'male', 'address': '7966 Retorno Malta, General Zaragoza, Ciudad de Mexico, Mexico', 'post_code': 11288, 'email': 'marcos.ulloa@example.com', 'username': 'tinykoala438', 'dob': '1997-07-24T14:44:37.446Z', 'registered_date': '2019-04-17T12:39:17.771Z', 'phone': '(641) 501 2368', 'picture': 'https://randomuser.me/api/portraits/med/men/22.jpg'}\n",
      "{'id': 'f9309576-17e9-4299-a75a-08a4a17f4041', 'first_name': 'Storm', 'last_name': 'Poulsen', 'gender': 'male', 'address': '8149 Rytterv√¶nget, Ishoej, Midtjylland, Denmark', 'post_code': 50307, 'email': 'storm.poulsen@example.com', 'username': 'goldenkoala571', 'dob': '1972-12-24T11:16:55.899Z', 'registered_date': '2006-10-22T09:30:10.047Z', 'phone': '92104209', 'picture': 'https://randomuser.me/api/portraits/med/men/75.jpg'}\n",
      "{'id': 'f9309576-17e9-4299-a75a-08a4a17f4041', 'first_name': 'Storm', 'last_name': 'Poulsen', 'gender': 'male', 'address': '8149 Rytterv√¶nget, Ishoej, Midtjylland, Denmark', 'post_code': 50307, 'email': 'storm.poulsen@example.com', 'username': 'goldenkoala571', 'dob': '1972-12-24T11:16:55.899Z', 'registered_date': '2006-10-22T09:30:10.047Z', 'phone': '92104209', 'picture': 'https://randomuser.me/api/portraits/med/men/75.jpg'}\n",
      "{'id': 'cea3f486-5674-43c3-87f7-cc318601c08f', 'first_name': '√úlk√º', 'last_name': 'Okur', 'gender': 'female', 'address': '3397 Mevlana Cd, Erzurum, Hakk√¢ri, Turkey', 'post_code': 85488, 'email': 'ulku.okur@example.com', 'username': 'smallladybug977', 'dob': '1981-07-29T14:28:44.734Z', 'registered_date': '2016-01-03T20:02:00.224Z', 'phone': '(734)-645-3102', 'picture': 'https://randomuser.me/api/portraits/med/women/48.jpg'}\n",
      "{'id': 'cea3f486-5674-43c3-87f7-cc318601c08f', 'first_name': '√úlk√º', 'last_name': 'Okur', 'gender': 'female', 'address': '3397 Mevlana Cd, Erzurum, Hakk√¢ri, Turkey', 'post_code': 85488, 'email': 'ulku.okur@example.com', 'username': 'smallladybug977', 'dob': '1981-07-29T14:28:44.734Z', 'registered_date': '2016-01-03T20:02:00.224Z', 'phone': '(734)-645-3102', 'picture': 'https://randomuser.me/api/portraits/med/women/48.jpg'}\n",
      "{'id': '0c94f257-a7f5-4412-8140-9d8860a5ef4c', 'first_name': 'ŸÖÿ≠ŸÖÿØÿπŸÑ€å', 'last_name': '€åÿßÿ≥ŸÖ€å', 'gender': 'male', 'address': '2672 Ÿæÿßÿ±⁄© ÿ∑ÿßŸÑŸÇÿßŸÜ€å, ⁄©ÿßÿ¥ÿßŸÜ, ÿß€åŸÑÿßŸÖ, Iran', 'post_code': 14307, 'email': 'mhmdaaly.ysmy@example.com', 'username': 'beautifulmeercat864', 'dob': '1979-02-10T10:51:29.685Z', 'registered_date': '2010-02-17T12:39:15.457Z', 'phone': '065-75632110', 'picture': 'https://randomuser.me/api/portraits/med/men/43.jpg'}\n",
      "{'id': '0c94f257-a7f5-4412-8140-9d8860a5ef4c', 'first_name': 'ŸÖÿ≠ŸÖÿØÿπŸÑ€å', 'last_name': '€åÿßÿ≥ŸÖ€å', 'gender': 'male', 'address': '2672 Ÿæÿßÿ±⁄© ÿ∑ÿßŸÑŸÇÿßŸÜ€å, ⁄©ÿßÿ¥ÿßŸÜ, ÿß€åŸÑÿßŸÖ, Iran', 'post_code': 14307, 'email': 'mhmdaaly.ysmy@example.com', 'username': 'beautifulmeercat864', 'dob': '1979-02-10T10:51:29.685Z', 'registered_date': '2010-02-17T12:39:15.457Z', 'phone': '065-75632110', 'picture': 'https://randomuser.me/api/portraits/med/men/43.jpg'}\n",
      "{'id': '74be9b6e-9fbe-4489-8e0f-71bd128bbc90', 'first_name': 'Gordon', 'last_name': 'Harrison', 'gender': 'male', 'address': '8523 Mcgowen St, Nampa, Montana, United States', 'post_code': 38184, 'email': 'gordon.harrison@example.com', 'username': 'organiclion654', 'dob': '1963-05-31T08:32:06.921Z', 'registered_date': '2003-01-31T23:27:02.100Z', 'phone': '(525) 949-9561', 'picture': 'https://randomuser.me/api/portraits/med/men/18.jpg'}\n",
      "{'id': '74be9b6e-9fbe-4489-8e0f-71bd128bbc90', 'first_name': 'Gordon', 'last_name': 'Harrison', 'gender': 'male', 'address': '8523 Mcgowen St, Nampa, Montana, United States', 'post_code': 38184, 'email': 'gordon.harrison@example.com', 'username': 'organiclion654', 'dob': '1963-05-31T08:32:06.921Z', 'registered_date': '2003-01-31T23:27:02.100Z', 'phone': '(525) 949-9561', 'picture': 'https://randomuser.me/api/portraits/med/men/18.jpg'}\n",
      "{'id': 'ce2d586a-7f7d-4900-9dac-eb9bde849bd9', 'first_name': 'Leonardo', 'last_name': 'Moya', 'gender': 'male', 'address': '6739 Viaducto Chiapas, Alfonso G. Calder√≥n (Pob. 7), Campeche, Mexico', 'post_code': 13949, 'email': 'leonardo.moya@example.com', 'username': 'yellowgorilla385', 'dob': '1996-10-18T18:57:29.444Z', 'registered_date': '2012-02-21T11:24:40.465Z', 'phone': '(690) 579 6351', 'picture': 'https://randomuser.me/api/portraits/med/men/90.jpg'}\n",
      "{'id': 'ce2d586a-7f7d-4900-9dac-eb9bde849bd9', 'first_name': 'Leonardo', 'last_name': 'Moya', 'gender': 'male', 'address': '6739 Viaducto Chiapas, Alfonso G. Calder√≥n (Pob. 7), Campeche, Mexico', 'post_code': 13949, 'email': 'leonardo.moya@example.com', 'username': 'yellowgorilla385', 'dob': '1996-10-18T18:57:29.444Z', 'registered_date': '2012-02-21T11:24:40.465Z', 'phone': '(690) 579 6351', 'picture': 'https://randomuser.me/api/portraits/med/men/90.jpg'}\n",
      "{'id': 'ddd8fb06-de08-47e9-b4fe-41a1d8bdd4d9', 'first_name': 'Liva', 'last_name': 'Christensen', 'gender': 'female', 'address': '8317 Tj√∏rnebjerg, Askeby, Hovedstaden, Denmark', 'post_code': 49172, 'email': 'liva.christensen@example.com', 'username': 'goldenleopard332', 'dob': '1955-03-21T16:14:05.816Z', 'registered_date': '2018-10-04T10:29:38.843Z', 'phone': '88057050', 'picture': 'https://randomuser.me/api/portraits/med/women/31.jpg'}\n",
      "{'id': 'ddd8fb06-de08-47e9-b4fe-41a1d8bdd4d9', 'first_name': 'Liva', 'last_name': 'Christensen', 'gender': 'female', 'address': '8317 Tj√∏rnebjerg, Askeby, Hovedstaden, Denmark', 'post_code': 49172, 'email': 'liva.christensen@example.com', 'username': 'goldenleopard332', 'dob': '1955-03-21T16:14:05.816Z', 'registered_date': '2018-10-04T10:29:38.843Z', 'phone': '88057050', 'picture': 'https://randomuser.me/api/portraits/med/women/31.jpg'}\n",
      "{'id': '4cb56936-e449-4551-a641-bf37c917d1dc', 'first_name': 'Ava', 'last_name': 'Wallace', 'gender': 'female', 'address': '4768 Manor Road, Kinsale, Roscommon, Ireland', 'post_code': 67634, 'email': 'ava.wallace@example.com', 'username': 'smallelephant928', 'dob': '1965-10-26T20:54:00.828Z', 'registered_date': '2021-01-26T08:54:55.706Z', 'phone': '061-664-7395', 'picture': 'https://randomuser.me/api/portraits/med/women/73.jpg'}\n",
      "{'id': '4cb56936-e449-4551-a641-bf37c917d1dc', 'first_name': 'Ava', 'last_name': 'Wallace', 'gender': 'female', 'address': '4768 Manor Road, Kinsale, Roscommon, Ireland', 'post_code': 67634, 'email': 'ava.wallace@example.com', 'username': 'smallelephant928', 'dob': '1965-10-26T20:54:00.828Z', 'registered_date': '2021-01-26T08:54:55.706Z', 'phone': '061-664-7395', 'picture': 'https://randomuser.me/api/portraits/med/women/73.jpg'}\n",
      "{'id': 'a73fcdc5-5ca8-4332-84db-b157ccfda288', 'first_name': 'Rishi', 'last_name': 'Padmanabha', 'gender': 'male', 'address': '104 Shakespeare Sarani, Mahbubnagar, Gujarat, India', 'post_code': 59356, 'email': 'rishi.padmanabha@example.com', 'username': 'happybird552', 'dob': '1951-05-23T19:27:06.563Z', 'registered_date': '2005-02-13T04:23:42.256Z', 'phone': '8635716672', 'picture': 'https://randomuser.me/api/portraits/med/men/7.jpg'}\n",
      "{'id': 'a73fcdc5-5ca8-4332-84db-b157ccfda288', 'first_name': 'Rishi', 'last_name': 'Padmanabha', 'gender': 'male', 'address': '104 Shakespeare Sarani, Mahbubnagar, Gujarat, India', 'post_code': 59356, 'email': 'rishi.padmanabha@example.com', 'username': 'happybird552', 'dob': '1951-05-23T19:27:06.563Z', 'registered_date': '2005-02-13T04:23:42.256Z', 'phone': '8635716672', 'picture': 'https://randomuser.me/api/portraits/med/men/7.jpg'}\n",
      "{'id': '48bede9c-b351-4f2a-9a27-48b7462cf84e', 'first_name': 'Fredrikke', 'last_name': 'Fjermestad', 'gender': 'female', 'address': '3124 Midt√•sen, S√¶b√∏vik, Troms - Romsa, Norway', 'post_code': '9068', 'email': 'fredrikke.fjermestad@example.com', 'username': 'orangekoala607', 'dob': '1999-09-30T22:33:14.633Z', 'registered_date': '2021-07-11T18:56:49.508Z', 'phone': '29756601', 'picture': 'https://randomuser.me/api/portraits/med/women/7.jpg'}\n",
      "{'id': '48bede9c-b351-4f2a-9a27-48b7462cf84e', 'first_name': 'Fredrikke', 'last_name': 'Fjermestad', 'gender': 'female', 'address': '3124 Midt√•sen, S√¶b√∏vik, Troms - Romsa, Norway', 'post_code': '9068', 'email': 'fredrikke.fjermestad@example.com', 'username': 'orangekoala607', 'dob': '1999-09-30T22:33:14.633Z', 'registered_date': '2021-07-11T18:56:49.508Z', 'phone': '29756601', 'picture': 'https://randomuser.me/api/portraits/med/women/7.jpg'}\n",
      "{'id': '3184a234-fd33-49fd-b3b0-38aa1fe7bc22', 'first_name': 'Aapo', 'last_name': 'Kivisto', 'gender': 'male', 'address': '9723 Nordenski√∂ldinkatu, Kalajoki, √Öland, Finland', 'post_code': 41699, 'email': 'aapo.kivisto@example.com', 'username': 'goldentiger670', 'dob': '2000-01-15T13:23:18.139Z', 'registered_date': '2010-08-11T16:48:35.706Z', 'phone': '06-243-421', 'picture': 'https://randomuser.me/api/portraits/med/men/60.jpg'}\n",
      "{'id': '3184a234-fd33-49fd-b3b0-38aa1fe7bc22', 'first_name': 'Aapo', 'last_name': 'Kivisto', 'gender': 'male', 'address': '9723 Nordenski√∂ldinkatu, Kalajoki, √Öland, Finland', 'post_code': 41699, 'email': 'aapo.kivisto@example.com', 'username': 'goldentiger670', 'dob': '2000-01-15T13:23:18.139Z', 'registered_date': '2010-08-11T16:48:35.706Z', 'phone': '06-243-421', 'picture': 'https://randomuser.me/api/portraits/med/men/60.jpg'}\n",
      "{'id': 'f3beeedd-a712-4a7c-910f-bfb1c4704303', 'first_name': 'William', 'last_name': 'Petersen', 'gender': 'male', 'address': '322 Skovbrynet, Tisvilde, Sj√¶lland, Denmark', 'post_code': 72972, 'email': 'william.petersen@example.com', 'username': 'happypanda871', 'dob': '1962-09-25T02:08:22.281Z', 'registered_date': '2016-08-12T23:52:46.572Z', 'phone': '78611864', 'picture': 'https://randomuser.me/api/portraits/med/men/75.jpg'}\n",
      "{'id': 'f3beeedd-a712-4a7c-910f-bfb1c4704303', 'first_name': 'William', 'last_name': 'Petersen', 'gender': 'male', 'address': '322 Skovbrynet, Tisvilde, Sj√¶lland, Denmark', 'post_code': 72972, 'email': 'william.petersen@example.com', 'username': 'happypanda871', 'dob': '1962-09-25T02:08:22.281Z', 'registered_date': '2016-08-12T23:52:46.572Z', 'phone': '78611864', 'picture': 'https://randomuser.me/api/portraits/med/men/75.jpg'}\n",
      "{'id': '17fac774-5283-4b94-9eb9-be3387db3df0', 'first_name': 'Dobrolyub', 'last_name': 'Horishko', 'gender': 'male', 'address': '2049 Silikatna, Pidgayci, Ivano-Frankivska, Ukraine', 'post_code': 79278, 'email': 'dobrolyub.horishko@example.com', 'username': 'bigelephant163', 'dob': '1970-04-29T14:38:56.357Z', 'registered_date': '2004-08-10T08:08:49.512Z', 'phone': '(068) K45-0822', 'picture': 'https://randomuser.me/api/portraits/med/men/46.jpg'}\n",
      "{'id': '17fac774-5283-4b94-9eb9-be3387db3df0', 'first_name': 'Dobrolyub', 'last_name': 'Horishko', 'gender': 'male', 'address': '2049 Silikatna, Pidgayci, Ivano-Frankivska, Ukraine', 'post_code': 79278, 'email': 'dobrolyub.horishko@example.com', 'username': 'bigelephant163', 'dob': '1970-04-29T14:38:56.357Z', 'registered_date': '2004-08-10T08:08:49.512Z', 'phone': '(068) K45-0822', 'picture': 'https://randomuser.me/api/portraits/med/men/46.jpg'}\n",
      "{'id': '15b10788-7f2b-4a02-89b9-052ed4c1c9e8', 'first_name': 'Spasoje', 'last_name': 'Popoviƒá', 'gender': 'male', 'address': '8011 Porodice Rankoviƒá, Arilje, Zajeƒçar, Serbia', 'post_code': 57831, 'email': 'spasoje.popovic@example.com', 'username': 'silverdog928', 'dob': '1974-10-28T00:11:29.173Z', 'registered_date': '2009-10-01T02:42:18.811Z', 'phone': '012-1498-017', 'picture': 'https://randomuser.me/api/portraits/med/men/17.jpg'}\n",
      "{'id': '15b10788-7f2b-4a02-89b9-052ed4c1c9e8', 'first_name': 'Spasoje', 'last_name': 'Popoviƒá', 'gender': 'male', 'address': '8011 Porodice Rankoviƒá, Arilje, Zajeƒçar, Serbia', 'post_code': 57831, 'email': 'spasoje.popovic@example.com', 'username': 'silverdog928', 'dob': '1974-10-28T00:11:29.173Z', 'registered_date': '2009-10-01T02:42:18.811Z', 'phone': '012-1498-017', 'picture': 'https://randomuser.me/api/portraits/med/men/17.jpg'}\n",
      "{'id': 'e9bcee8c-474c-4c8d-86a5-88f8a37cbf78', 'first_name': 'Angie', 'last_name': 'Carr', 'gender': 'female', 'address': '6070 London Road, Aberdeen, Highlands and Islands, United Kingdom', 'post_code': 'OD2X 8UP', 'email': 'angie.carr@example.com', 'username': 'beautifulbear302', 'dob': '1976-05-12T16:50:00.527Z', 'registered_date': '2017-08-14T15:11:08.893Z', 'phone': '017684 40931', 'picture': 'https://randomuser.me/api/portraits/med/women/4.jpg'}\n",
      "{'id': 'e9bcee8c-474c-4c8d-86a5-88f8a37cbf78', 'first_name': 'Angie', 'last_name': 'Carr', 'gender': 'female', 'address': '6070 London Road, Aberdeen, Highlands and Islands, United Kingdom', 'post_code': 'OD2X 8UP', 'email': 'angie.carr@example.com', 'username': 'beautifulbear302', 'dob': '1976-05-12T16:50:00.527Z', 'registered_date': '2017-08-14T15:11:08.893Z', 'phone': '017684 40931', 'picture': 'https://randomuser.me/api/portraits/med/women/4.jpg'}\n",
      "{'id': '55c9247b-3a61-4933-bc97-5a0a5f650f36', 'first_name': 'Volkan', 'last_name': 'Poyrazoƒülu', 'gender': 'male', 'address': '6526 Doktorlar Cd, ≈ûanlƒ±urfa, Antalya, Turkey', 'post_code': 40579, 'email': 'volkan.poyrazoglu@example.com', 'username': 'happykoala807', 'dob': '1975-10-07T03:05:04.272Z', 'registered_date': '2011-10-29T10:26:44.632Z', 'phone': '(798)-992-5706', 'picture': 'https://randomuser.me/api/portraits/med/men/30.jpg'}\n",
      "{'id': '55c9247b-3a61-4933-bc97-5a0a5f650f36', 'first_name': 'Volkan', 'last_name': 'Poyrazoƒülu', 'gender': 'male', 'address': '6526 Doktorlar Cd, ≈ûanlƒ±urfa, Antalya, Turkey', 'post_code': 40579, 'email': 'volkan.poyrazoglu@example.com', 'username': 'happykoala807', 'dob': '1975-10-07T03:05:04.272Z', 'registered_date': '2011-10-29T10:26:44.632Z', 'phone': '(798)-992-5706', 'picture': 'https://randomuser.me/api/portraits/med/men/30.jpg'}\n",
      "{'id': 'b972d614-7391-4065-b1db-8741f42c3135', 'first_name': 'Melina', 'last_name': 'Anƒëeliƒá', 'gender': 'female', 'address': '7132 Porodice Stankoviƒá, Smederevo, Rasina, Serbia', 'post_code': 45560, 'email': 'melina.andelic@example.com', 'username': 'angrydog754', 'dob': '1965-03-05T10:44:19.025Z', 'registered_date': '2008-09-13T06:22:56.371Z', 'phone': '033-8651-081', 'picture': 'https://randomuser.me/api/portraits/med/women/88.jpg'}\n",
      "{'id': 'b972d614-7391-4065-b1db-8741f42c3135', 'first_name': 'Melina', 'last_name': 'Anƒëeliƒá', 'gender': 'female', 'address': '7132 Porodice Stankoviƒá, Smederevo, Rasina, Serbia', 'post_code': 45560, 'email': 'melina.andelic@example.com', 'username': 'angrydog754', 'dob': '1965-03-05T10:44:19.025Z', 'registered_date': '2008-09-13T06:22:56.371Z', 'phone': '033-8651-081', 'picture': 'https://randomuser.me/api/portraits/med/women/88.jpg'}\n",
      "{'id': 'a9bcf4cc-ecdf-4e91-a873-f55327a29be3', 'first_name': 'Darsh', 'last_name': 'Shukla', 'gender': 'male', 'address': '7408 Bannerghatta Rd, Bulandshahr, Madhya Pradesh, India', 'post_code': 34825, 'email': 'darsh.shukla@example.com', 'username': 'brownpeacock151', 'dob': '1962-02-21T18:06:15.714Z', 'registered_date': '2007-02-27T18:35:26.311Z', 'phone': '7886778966', 'picture': 'https://randomuser.me/api/portraits/med/men/75.jpg'}\n",
      "{'id': 'a9bcf4cc-ecdf-4e91-a873-f55327a29be3', 'first_name': 'Darsh', 'last_name': 'Shukla', 'gender': 'male', 'address': '7408 Bannerghatta Rd, Bulandshahr, Madhya Pradesh, India', 'post_code': 34825, 'email': 'darsh.shukla@example.com', 'username': 'brownpeacock151', 'dob': '1962-02-21T18:06:15.714Z', 'registered_date': '2007-02-27T18:35:26.311Z', 'phone': '7886778966', 'picture': 'https://randomuser.me/api/portraits/med/men/75.jpg'}\n",
      "{'id': '5132e740-8c56-4098-8ff8-b14845e31ac9', 'first_name': 'Lewis', 'last_name': 'Morris', 'gender': 'male', 'address': '2573 Prestons Road, Napier, Northland, New Zealand', 'post_code': 12447, 'email': 'lewis.morris@example.com', 'username': 'happydog497', 'dob': '1958-03-04T11:32:42.216Z', 'registered_date': '2007-06-26T18:58:10.827Z', 'phone': '(397)-618-5296', 'picture': 'https://randomuser.me/api/portraits/med/men/29.jpg'}\n",
      "{'id': '5132e740-8c56-4098-8ff8-b14845e31ac9', 'first_name': 'Lewis', 'last_name': 'Morris', 'gender': 'male', 'address': '2573 Prestons Road, Napier, Northland, New Zealand', 'post_code': 12447, 'email': 'lewis.morris@example.com', 'username': 'happydog497', 'dob': '1958-03-04T11:32:42.216Z', 'registered_date': '2007-06-26T18:58:10.827Z', 'phone': '(397)-618-5296', 'picture': 'https://randomuser.me/api/portraits/med/men/29.jpg'}\n",
      "{'id': '8b844b40-80a0-47fa-a06c-1ff9679d6afe', 'first_name': 'Hartmuth', 'last_name': 'Hannemann', 'gender': 'male', 'address': '8077 Kirchgasse, Freyburg (Unstrut), Berlin, Germany', 'post_code': 30065, 'email': 'hartmuth.hannemann@example.com', 'username': 'reddog676', 'dob': '1968-03-18T01:21:11.088Z', 'registered_date': '2013-10-27T23:29:43.606Z', 'phone': '0880-8020852', 'picture': 'https://randomuser.me/api/portraits/med/men/19.jpg'}\n",
      "{'id': '8b844b40-80a0-47fa-a06c-1ff9679d6afe', 'first_name': 'Hartmuth', 'last_name': 'Hannemann', 'gender': 'male', 'address': '8077 Kirchgasse, Freyburg (Unstrut), Berlin, Germany', 'post_code': 30065, 'email': 'hartmuth.hannemann@example.com', 'username': 'reddog676', 'dob': '1968-03-18T01:21:11.088Z', 'registered_date': '2013-10-27T23:29:43.606Z', 'phone': '0880-8020852', 'picture': 'https://randomuser.me/api/portraits/med/men/19.jpg'}\n"
     ]
    }
   ],
   "source": [
    "# Function Streaming Data from API\n",
    "stream_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ETL (Extract, Transform, Load) ‡πÅ‡∏ö‡∏ö Real-time** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏±‡∏Å‡∏Ñ‡∏∑‡∏≠ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (user) ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÉ‡∏ô Kafka ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á, ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á, ‡πÅ‡∏•‡πâ‡∏ß‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from cassandra.cluster import Cluster\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Spark\n",
    "def create_spark_connection():\n",
    "    s_conn = None\n",
    "\n",
    "    try:\n",
    "        s_conn = (SparkSession.builder \n",
    "            .appName('SparkDataStreaming')\n",
    "            .master(\"spark://spark-master:7077\")\n",
    "            .config('spark.jars.packages', # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏û‡∏Ñ‡πÄ‡∏Å‡∏à‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Spark\n",
    "                    \"com.datastax.spark:spark-cassandra-connector_2.12:3.5.0,\" # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏û‡∏Ñ‡πÄ‡∏Å‡∏à‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Cassandra\n",
    "                    \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\") # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏û‡∏Ñ‡πÄ‡∏Å‡∏à‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Kafka \n",
    "            .config('spark.cassandra.connection.host', 'localhost') # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Cassandra\n",
    "            .getOrCreate())\n",
    "        \n",
    "        s_conn.sparkContext.setLogLevel(\"ERROR\")\n",
    "        logging.info(\"Spark connection created successfully!\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Couldn't create the spark session due to exception {e}\")\n",
    "\n",
    "    return s_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Kafka\n",
    "def connect_to_kafka(spark_conn):\n",
    "    spark_df = None\n",
    "    try:\n",
    "        spark_df = (spark_conn.readStream \\\n",
    "            .format('kafka') \\\n",
    "            .option('kafka.bootstrap.servers', 'broker:29092') # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Kafka Broker\n",
    "            .option('subscribe', 'users_created') # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á Kafka Topic ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤\n",
    "            .option('startingOffsets', 'earliest') # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà earliest (‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô) ‡∏´‡∏£‡∏∑‡∏≠ latest (‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)\n",
    "            .option(\"maxOffsetsPerTrigger\", 100)  # ‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏µ‡∏•‡∏∞ 50 records\n",
    "            .load())\n",
    "        logging.info(\"kafka dataframe created successfully\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"kafka dataframe could not be created because: {e}\")\n",
    "\n",
    "    return spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Cassandra\n",
    "def create_cassandra_connection():\n",
    "    try:\n",
    "        # connecting to the cassandra cluster\n",
    "        cluster = Cluster(contact_points=['cassandra'], port=9042) # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà hostname ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Cassandra\n",
    "        cas_session = cluster.connect() # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠\n",
    "\n",
    "        logging.info(\"Connected to Cassandra!\")\n",
    "        return cas_session\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not create cassandra connection due to {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keyspace(session):\n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Database / Schema ‡∏ö‡∏ô Cassandra ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ Keyspace\n",
    "    session.execute(\"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS spark_streams\n",
    "        WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};\n",
    "    \"\"\")\n",
    "\n",
    "    print(\"Keyspace created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(session):\n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Table\n",
    "    session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS spark_streams.created_users (\n",
    "        id UUID PRIMARY KEY,\n",
    "        first_name TEXT,\n",
    "        last_name TEXT,\n",
    "        gender TEXT,\n",
    "        address TEXT,\n",
    "        post_code TEXT,\n",
    "        email TEXT,\n",
    "        username TEXT,\n",
    "        registered_date TEXT,\n",
    "        phone TEXT,\n",
    "        picture TEXT) WITH default_time_to_live = 1200;\n",
    "    \"\"\")\n",
    "\n",
    "    print(\"Table created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ Spark ‡πÅ‡∏•‡∏∞ Data Quality Checks\n",
    "def create_selection_df_from_kafka(spark_df):\n",
    "    \"\"\"\n",
    "    ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Kafka ‡πÄ‡∏õ‡πá‡∏ô Spark DataFrame ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥ Data Quality Checks\n",
    "    - Schema Enforcement\n",
    "    - Missing Value Check\n",
    "    - Business Rule Validation (regex, allowed values)\n",
    "    - Deduplication\n",
    "    - ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô validation ‡πÑ‡∏õ Dead-letter topic (optional)\n",
    "    \n",
    "    Args:\n",
    "        spark_df: input streaming DataFrame ‡∏à‡∏≤‡∏Å Kafka\n",
    "        kafka_producer_invalid: KafkaProducer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• invalid (optional)\n",
    "    \n",
    "    Returns:\n",
    "        validated_df: Spark DataFrame ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠ (validated)\n",
    "    \"\"\"\n",
    "    # -------------------- 1. Define Schema --------------------\n",
    "    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤\n",
    "    schema = StructType([\n",
    "        StructField(\"id\", StringType(), False),\n",
    "        StructField(\"first_name\", StringType(), False),\n",
    "        StructField(\"last_name\", StringType(), False),\n",
    "        StructField(\"gender\", StringType(), False),\n",
    "        StructField(\"address\", StringType(), False),\n",
    "        StructField(\"post_code\", StringType(), False),\n",
    "        StructField(\"email\", StringType(), False),\n",
    "        StructField(\"username\", StringType(), False),\n",
    "        StructField(\"registered_date\", StringType(), False),\n",
    "        StructField(\"phone\", StringType(), False),\n",
    "        StructField(\"picture\", StringType(), False)\n",
    "    ])\n",
    "\n",
    "    # -------------------- 2. Parse JSON and Enforce Schema --------------------\n",
    "    # ‡∏î‡∏∂‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å kafka ‡πÄ‡∏õ‡πá‡∏ô Spark DataFrame \n",
    "    df = (spark_df.selectExpr(\"CAST(value AS STRING)\") # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå value ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô String \n",
    "        .select(from_json(col('value'), schema).alias('data')).select(\"data.*\")) # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å json ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô value ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° schema\n",
    "    logging.info(\"Schema applied and JSON parsed.\")\n",
    "\n",
    "    # -------------------- 3. Missing Value Check --------------------\n",
    "    df_non_null = df.dropna(subset=[\"id\", \"email\", \"registered_date\"]) # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô null ‡πÉ‡∏ô col ‡∏û‡∏ß‡∏Å‡∏ô‡∏µ‡πâ\n",
    "    logging.info(\"Dropped records with null id, email, or registered_date.\")\n",
    "\n",
    "    # -------------------- 4. Business Rule Validation --------------------\n",
    "    df_valid = df_non_null.filter( # filter ‡πÅ‡∏Ñ‡πà‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏° regex ‡∏ï‡∏≤‡∏°‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ\n",
    "        col(\"email\").rlike(r\".+@.+\\..+\") & # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á email pattern\n",
    "        col(\"gender\").isin(\"male\", \"female\") & # ‡∏à‡∏∞‡∏°‡∏µ‡πÅ‡∏Ñ‡πà 2 ‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "        col(\"id\").rlike(\"^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$\")\n",
    "    )\n",
    "    logging.info(\"Applied business rule validation.\")\n",
    "\n",
    "    # -------------------- 5. Deduplicate --------------------\n",
    "    df_deduped = df_valid.dropDuplicates([\"id\"]) # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ id ‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô\n",
    "    logging.info(\"Deduplicated based on id.\")\n",
    "\n",
    "    return df_deduped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-b8ad9421-e984-454d-99d0-2d47bcc1c289;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.4.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.3 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector_2.12/3.5.0/spark-cassandra-connector_2.12-3.5.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector_2.12;3.5.0!spark-cassandra-connector_2.12.jar (9646ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.1/spark-sql-kafka-0-10_2.12-3.5.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1!spark-sql-kafka-0-10_2.12.jar (2598ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector-driver_2.12/3.5.0/spark-cassandra-connector-driver_2.12-3.5.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0!spark-cassandra-connector-driver_2.12.jar (4293ms)\n",
      "downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-collection-compat_2.12/2.11.0/scala-collection-compat_2.12-2.11.0.jar ...\n",
      "\t[SUCCESSFUL ] org.scala-lang.modules#scala-collection-compat_2.12;2.11.0!scala-collection-compat_2.12.jar (1287ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-core-shaded/4.13.0/java-driver-core-shaded-4.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-core-shaded;4.13.0!java-driver-core-shaded.jar (28898ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-mapper-runtime/4.13.0/java-driver-mapper-runtime-4.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-mapper-runtime;4.13.0!java-driver-mapper-runtime.jar(bundle) (771ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.10/commons-lang3-3.10.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-lang3;3.10!commons-lang3.jar (2914ms)\n",
      "downloading https://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar ...\n",
      "\t[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.8!paranamer.jar(bundle) (608ms)\n",
      "downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.11/scala-reflect-2.12.11.jar ...\n",
      "\t[SUCCESSFUL ] org.scala-lang#scala-reflect;2.12.11!scala-reflect.jar (13092ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/native-protocol/1.5.0/native-protocol-1.5.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#native-protocol;1.5.0!native-protocol.jar(bundle) (851ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-shaded-guava/25.1-jre-graal-sub-1/java-driver-shaded-guava-25.1-jre-graal-sub-1.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1!java-driver-shaded-guava.jar (4028ms)\n",
      "downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.1/config-1.4.1.jar ...\n",
      "\t[SUCCESSFUL ] com.typesafe#config;1.4.1!config.jar(bundle) (1594ms)\n",
      "downloading https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/4.1.18/metrics-core-4.1.18.jar ...\n",
      "\t[SUCCESSFUL ] io.dropwizard.metrics#metrics-core;4.1.18!metrics-core.jar(bundle) (7694ms)\n",
      "downloading https://repo1.maven.org/maven2/org/hdrhistogram/HdrHistogram/2.1.12/HdrHistogram-2.1.12.jar ...\n",
      "\t[SUCCESSFUL ] org.hdrhistogram#HdrHistogram;2.1.12!HdrHistogram.jar(bundle) (2844ms)\n",
      "downloading https://repo1.maven.org/maven2/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar ...\n",
      "\t[SUCCESSFUL ] org.reactivestreams#reactive-streams;1.0.3!reactive-streams.jar (3195ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar ...\n",
      "\t[SUCCESSFUL ] com.github.stephenc.jcip#jcip-annotations;1.0-1!jcip-annotations.jar (3293ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar ...\n",
      "\t[SUCCESSFUL ] com.github.spotbugs#spotbugs-annotations;3.1.12!spotbugs-annotations.jar (2044ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.2!jsr305.jar (1393ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-query-builder/4.13.0/java-driver-query-builder-4.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-query-builder;4.13.0!java-driver-query-builder.jar(bundle) (7634ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.1/spark-token-provider-kafka-0-10_2.12-3.5.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1!spark-token-provider-kafka-0-10_2.12.jar (2105ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.4.1/kafka-clients-3.4.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.kafka#kafka-clients;3.4.1!kafka-clients.jar (26683ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-pool2;2.11.1!commons-pool2.jar (1110ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.4/hadoop-client-runtime-3.3.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.4!hadoop-client-runtime.jar (122840ms)\n",
      "downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...\n",
      "\t[SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (3186ms)\n",
      "downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.10.3/snappy-java-1.1.10.3.jar ...\n",
      "\t[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.10.3!snappy-java.jar(bundle) (9134ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/2.0.7/slf4j-api-2.0.7.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;2.0.7!slf4j-api.jar (725ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.4/hadoop-client-api-3.3.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.4!hadoop-client-api.jar (103769ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...\n",
      "\t[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (829ms)\n",
      ":: resolution report :: resolve 49940ms :: artifacts dl 369093ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.5.0 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.3 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.slf4j#slf4j-api;1.7.26 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.2] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   30  |   29  |   29  |   2   ||   28  |   28  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-b8ad9421-e984-454d-99d0-2d47bcc1c289\n",
      "\tconfs: [default]\n",
      "\t28 artifacts copied, 0 already retrieved (75061kB/134ms)\n",
      "25/09/11 08:54:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/11 08:54:59 WARN Utils: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n",
      "2025-09-11 08:55:00,363 - INFO - Spark connection created successfully!\n",
      "2025-09-11 08:55:04,904 - INFO - kafka dataframe created successfully\n",
      "2025-09-11 08:55:06,038 - INFO - Schema applied and JSON parsed.\n",
      "2025-09-11 08:55:06,108 - INFO - Dropped records with null id, email, or registered_date.\n",
      "2025-09-11 08:55:06,205 - INFO - Applied business rule validation.\n",
      "2025-09-11 08:55:06,235 - INFO - Deduplicated based on id.\n",
      "2025-09-11 08:55:06,245 - WARNING - Cluster.__init__ called with contact_points specified, but no load_balancing_policy. In the next major version, this will raise an error; please specify a load-balancing policy. (contact_points = ['cassandra'], lbp = None)\n",
      "2025-09-11 08:55:06,662 - WARNING - Downgrading core protocol version from 66 to 65 for 172.18.0.3:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
      "2025-09-11 08:55:06,675 - WARNING - Downgrading core protocol version from 65 to 5 for 172.18.0.3:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
      "2025-09-11 08:55:06,749 - INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '172.18.0.3:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes\n",
      "2025-09-11 08:55:06,873 - INFO - Connected to Cassandra!\n",
      "2025-09-11 08:55:06,943 - INFO - Streaming is being started...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyspace created successfully!\n",
      "Table created successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/11 08:55:48 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: CassandraBulkWrite(org.apache.spark.sql.SparkSession@39cc8b75,com.datastax.spark.connector.cql.CassandraConnector@68d0775,TableDef(spark_streams,created_users,ArrayBuffer(ColumnDef(id,PartitionKeyColumn,UUIDType)),ArrayBuffer(),Stream(ColumnDef(address,RegularColumn,VarCharType), ColumnDef(email,RegularColumn,VarCharType), ColumnDef(first_name,RegularColumn,VarCharType), ColumnDef(gender,RegularColumn,VarCharType), ColumnDef(last_name,RegularColumn,VarCharType), ColumnDef(phone,RegularColumn,VarCharType), ColumnDef(picture,RegularColumn,VarCharType), ColumnDef(post_code,RegularColumn,VarCharType), ColumnDef(registered_date,RegularColumn,VarCharType), ColumnDef(username,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(BytesInBatch(1024),1000,Partition,LOCAL_QUORUM,false,false,5,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(id,StringType,true),StructField(first_name,StringType,true),StructField(last_name,StringType,true),StructField(gender,StringType,true),StructField(address,StringType,true),StructField(post_code,StringType,true),StructField(email,StringType,true),StructField(username,StringType,true),StructField(registered_date,StringType,true),StructField(phone,StringType,true),StructField(picture,StringType,true)),org.apache.spark.SparkConf@459b7e05)] is aborting.\n",
      "25/09/11 08:55:48 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: CassandraBulkWrite(org.apache.spark.sql.SparkSession@39cc8b75,com.datastax.spark.connector.cql.CassandraConnector@68d0775,TableDef(spark_streams,created_users,ArrayBuffer(ColumnDef(id,PartitionKeyColumn,UUIDType)),ArrayBuffer(),Stream(ColumnDef(address,RegularColumn,VarCharType), ColumnDef(email,RegularColumn,VarCharType), ColumnDef(first_name,RegularColumn,VarCharType), ColumnDef(gender,RegularColumn,VarCharType), ColumnDef(last_name,RegularColumn,VarCharType), ColumnDef(phone,RegularColumn,VarCharType), ColumnDef(picture,RegularColumn,VarCharType), ColumnDef(post_code,RegularColumn,VarCharType), ColumnDef(registered_date,RegularColumn,VarCharType), ColumnDef(username,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(BytesInBatch(1024),1000,Partition,LOCAL_QUORUM,false,false,5,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(id,StringType,true),StructField(first_name,StringType,true),StructField(last_name,StringType,true),StructField(gender,StringType,true),StructField(address,StringType,true),StructField(post_code,StringType,true),StructField(email,StringType,true),StructField(username,StringType,true),StructField(registered_date,StringType,true),StructField(phone,StringType,true),StructField(picture,StringType,true)),org.apache.spark.SparkConf@459b7e05)] aborted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 08:56:06,901 - WARNING - Host 172.18.0.3:9042 has been marked down\n",
      "2025-09-11 08:56:08,050 - WARNING - [control connection] Error connecting to 172.18.0.3:9042:\n",
      "Traceback (most recent call last):\n",
      "  File \"cassandra/cluster.py\", line 3577, in cassandra.cluster.ControlConnection._reconnect_internal\n",
      "  File \"cassandra/cluster.py\", line 3599, in cassandra.cluster.ControlConnection._try_connect\n",
      "  File \"cassandra/cluster.py\", line 1670, in cassandra.cluster.Cluster.connection_factory\n",
      "  File \"cassandra/connection.py\", line 846, in cassandra.connection.Connection.factory\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/cassandra/io/libevreactor.py\", line 266, in __init__\n",
      "    self._connect_socket()\n",
      "  File \"cassandra/connection.py\", line 951, in cassandra.connection.Connection._connect_socket\n",
      "OSError: [Errno 113] Tried connecting to [('172.18.0.3', 9042)]. Last error: No route to host\n",
      "2025-09-11 08:56:08,054 - WARNING - Error attempting to reconnect to 172.18.0.3:9042, scheduling retry in 1.96 seconds: [Errno 113] Tried connecting to [('172.18.0.3', 9042)]. Last error: No route to host\n",
      "2025-09-11 08:56:13,169 - WARNING - Error attempting to reconnect to 172.18.0.3:9042, scheduling retry in 4.4 seconds: [Errno 113] Tried connecting to [('172.18.0.3', 9042)]. Last error: No route to host\n",
      "2025-09-11 08:56:19,314 - WARNING - Error attempting to reconnect to 172.18.0.3:9042, scheduling retry in 8.0 seconds: [Errno 113] Tried connecting to [('172.18.0.3', 9042)]. Last error: No route to host\n",
      "2025-09-11 08:56:30,451 - WARNING - Error attempting to reconnect to 172.18.0.3:9042, scheduling retry in 17.12 seconds: [Errno 113] Tried connecting to [('172.18.0.3', 9042)]. Last error: No route to host\n"
     ]
    }
   ],
   "source": [
    "# create spark connection\n",
    "spark_conn = create_spark_connection() # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Spark\n",
    "\n",
    "if spark_conn is not None:\n",
    "        # connect to kafka with spark connection\n",
    "        spark_df = connect_to_kafka(spark_conn) # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Kafka\n",
    "        selection_df = create_selection_df_from_kafka(spark_df) # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Kafka\n",
    "        session = create_cassandra_connection() # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Cassandra\n",
    "\n",
    "        # Testing Data Flow on Console\n",
    "        # query = (selection_df\n",
    "        #  .writeStream\n",
    "        #  .format(\"console\")\n",
    "        #  .outputMode(\"append\")\n",
    "        #  .start())\n",
    "\n",
    "        # query.awaitTermination(30) # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ 30s ‡πÉ‡∏´‡πâ query data\n",
    "        # query.stop() # stop streaming query ‡∏´‡∏•‡∏±‡∏á 30s\n",
    "\n",
    "        if session is not None:\n",
    "            create_keyspace(session) # ‡∏™‡∏£‡πâ‡∏≤‡∏á Database / Schema ‡∏ö‡∏ô Cassandra ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ Keyspace\n",
    "            create_table(session) # ‡∏™‡∏£‡πâ‡∏≤‡∏á Table\n",
    "\n",
    "            logging.info(\"Streaming is being started...\")\n",
    "\n",
    "            # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á Database\n",
    "            streaming_query = (selection_df.writeStream\n",
    "                               .format(\"org.apache.spark.sql.cassandra\")\n",
    "                               .option('checkpointLocation', '/tmp/checkpoint')\n",
    "                               .option('keyspace', 'spark_streams')\n",
    "                               .option('table', 'created_users')\n",
    "                               .option(\"spark.cassandra.connection.host\", \"cassandra\")\n",
    "                               .option(\"spark.cassandra.connection.port\", \"9042\")\n",
    "                               .option(\"spark.cassandra.connection.local_dc\", \"datacenter1\")\n",
    "                               .trigger(processingTime=\"10 seconds\") # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏∏‡∏Å‡πÜ 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                               .start())\n",
    "\n",
    "            streaming_query.awaitTermination(30) # ‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î‡πÅ‡∏•‡πâ‡∏ß query data\n",
    "            streaming_query.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
