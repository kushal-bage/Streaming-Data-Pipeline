{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Real Time Data Engineering Projects**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£ (end-to-end) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á data engineering pipeline ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô ingestion, streaming, processing ‡πÑ‡∏õ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô real-time processing ‡πÅ‡∏•‡∏∞ containerized deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏£‡∏∞‡∏ö‡∏ö (System Architecture)**\n",
    "\n",
    "‡∏°‡∏µ component ‡∏´‡∏•‡∏±‡∏Å‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:\n",
    "\n",
    "- **Data Source**: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å API ‡πÄ‡∏ä‡πà‡∏ô randomuser.me ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á (dummy data) \n",
    "\n",
    "- **Apache Airflow**: ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà orchestration ‡∏Ç‡∏≠‡∏á pipeline ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà fetch ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏ô PostgreSQL \n",
    "\n",
    "- **Kafka + Zookeeper**: ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö streaming ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å PostgreSQL ‡πÑ‡∏õ‡∏¢‡∏±‡∏á processing engine \n",
    "\n",
    "- **Control Center & Schema Registry**: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏π‡πÅ‡∏• schema ‡πÅ‡∏•‡∏∞ monitoring Kafka streams \n",
    "\n",
    "- **Apache Spark**: ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (stream processing) ‡∏ú‡πà‡∏≤‡∏ô cluster (master/worker nodes) \n",
    "\n",
    "- **Cassandra**: ‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Orchestration: Apache Airflow\n",
    "\n",
    "- Streaming: Apache Kafka & Zookeeper\n",
    "\n",
    "- Processing: Apache Spark\n",
    "\n",
    "- Storage: PostgreSQL (‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•), Cassandra (‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•)\n",
    "\n",
    "- Containerization: Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå **Kafka ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Data Engineer)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1. Kafka ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?**\n",
    "\n",
    "- Kafka = ‡∏£‡∏∞‡∏ö‡∏ö distributed event streaming platform\n",
    "  ‚Üí ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á, ‡πÄ‡∏Å‡πá‡∏ö ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö real-time\n",
    "\n",
    "- ‡∏°‡∏±‡∏ô‡∏ó‡∏≥‡∏ï‡∏±‡∏ß‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô message broker (‡∏ó‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏≤‡∏á)\n",
    "\n",
    "- ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞‡πÉ‡∏ô‡∏á‡∏≤‡∏ô real-time analytics, log streaming, data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2. ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏´‡∏•‡∏±‡∏Å (Concepts)**\n",
    "\n",
    "‡∏•‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏õ‡πá‡∏ô \"‡∏´‡πâ‡∏≠‡∏á chat\" üëá\n",
    "\n",
    "- **Producer** ‚Üí ‡∏Ñ‡∏ô‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô Kafka)\n",
    "\n",
    "- **Consumer** ‚Üí ‡∏Ñ‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÉ‡∏ä‡πâ)\n",
    "\n",
    "- **Topic** ‚Üí ‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ (channel ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á/‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)\n",
    "\n",
    "- **Broker** ‚Üí Server ‡∏Ç‡∏≠‡∏á Kafka ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö topic\n",
    "\n",
    "- **Cluster** ‚Üí ‡∏Å‡∏•‡∏∏‡πà‡∏° broker ‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏ï‡∏±‡∏ß\n",
    "\n",
    "- **Partition** ‚Üí ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á topic ‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠ scale (‡πÅ‡∏ï‡πà‡∏•‡∏∞ partition ‡∏Ñ‡∏∑‡∏≠‡∏ó‡πà‡∏≠‡πÅ‡∏¢‡∏Å)\n",
    "\n",
    "- **Offset** ‚Üí ‡πÄ‡∏•‡∏Ç‡∏ö‡∏≠‡∏Å‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡∏≠‡∏á message ‡πÉ‡∏ô partition\n",
    "\n",
    "üëâ Keyword: Publish‚ÄìSubscribe system\n",
    "Producer ‡∏¢‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Üí Kafka ‚Üí Consumer ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3. Kafka Data Flow**\n",
    "\n",
    "1. Producer ‡∏™‡∏£‡πâ‡∏≤‡∏á event ‚Üí ‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏ó‡∏µ‡πà Kafka topic\n",
    "\n",
    "2. Kafka ‡πÄ‡∏Å‡πá‡∏ö event ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô log ‡πÅ‡∏ö‡∏ö append-only\n",
    "\n",
    "3. Consumer subscribe topic ‚Üí ‡∏≠‡πà‡∏≤‡∏ô event ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö offset\n",
    "\n",
    "4. Data ‡∏ñ‡∏π‡∏Å process ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ DB, Data Lake, Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡πá‡∏Ñ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö version ‡∏Ç‡∏≠‡∏á Python ‡πÅ‡∏•‡∏∞ Spark ‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å Docker Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.6\n",
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.5.1\n",
      "      /_/\n",
      "                        \n",
      "Using Scala version 2.12.18, OpenJDK 64-Bit Server VM, 11.0.28\n",
      "Branch HEAD\n",
      "Compiled by user heartsavior on 2024-02-15T11:24:58Z\n",
      "Revision fd86f85e181fc2dc0f50a096855acf83a6cc5d9c\n",
      "Url https://github.com/apache/spark\n",
      "Type --help for more information.\n"
     ]
    }
   ],
   "source": [
    "!python3 --version\n",
    "!spark-submit --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "res = requests.get(\"https://randomuser.me/api/\")\n",
    "res = res.json() # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô json\n",
    "res = res['results'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
